{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpythondataconda8971416e9bae4e8197b8a061b72f9dc8",
   "display_name": "Python 3.6.9 64-bit ('PythonData': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_most_common_words(textStream):\n",
    "    ''' Vectorizes words in textStream and then returns the 100 most unigrams'''\n",
    "\n",
    "    #init vectorizer\n",
    "    ngram_vectors = CountVectorizer(analyzer='word', \n",
    "                                    ngram_range=(1, 1), \n",
    "                                    min_df=1,\n",
    "                                    stop_words='english')\n",
    "    \n",
    "    #make textStream into an iterable for fit_transform\n",
    "    textStream = [textStream]\n",
    "    \n",
    "    #build vector array\n",
    "    X = ngram_vectors.fit_transform(textStream)\n",
    "\n",
    "    #get ngram vocabulary\n",
    "    vocab = ngram_vectors.get_feature_names()\n",
    "\n",
    "    #get ngram counts\n",
    "    counts = X.sum(axis=0).A1\n",
    "\n",
    "    #get frequency distribution of all ngrams and their respective counts\n",
    "    freq_distribution = Counter(dict(zip(vocab, counts)))\n",
    "\n",
    "    #get 100 most common ngrams, with their respective count\n",
    "    most_common_words = freq_distribution.most_common(100)\n",
    "\n",
    "    return most_common_words\n",
    "\n",
    "def read_file(text_file):\n",
    "    ''' Reads passed text_file from filesystem'''\n",
    "    file = open(text_file,mode='r',encoding='UTF-8')\n",
    "    file_contents = file.read()\n",
    "    file.close()\n",
    "    return file_contents\n",
    "\n",
    "def format_tuple(input_tuple):\n",
    "    ''' formats the returned tuple into a dictionary object '''\n",
    "    dict_entry = { 'text': input_tuple[0],\n",
    "                    'value': str(input_tuple[1])}\n",
    "    return dict_entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 3116)\t13\n  (0, 1685)\t67\n  (0, 4389)\t697\n  (0, 1965)\t600\n  (0, 3216)\t220\n  (0, 697)\t15\n  (0, 2204)\t819\n  (0, 1855)\t26\n  (0, 4114)\t593\n  (0, 2271)\t202\n  (0, 965)\t510\n  (0, 651)\t3\n  (0, 2173)\t73\n  (0, 3429)\t369\n  (0, 3730)\t484\n  (0, 260)\t11\n  (0, 4919)\t69\n  (0, 3912)\t18\n  (0, 4289)\t43\n  (0, 4676)\t188\n  (0, 4812)\t1\n  (0, 4135)\t48\n  (0, 5687)\t682\n  (0, 188)\t8\n  (0, 1037)\t8\n  :\t:\n  (0, 1201)\t1\n  (0, 3628)\t1\n  (0, 3627)\t1\n  (0, 3616)\t1\n  (0, 3521)\t1\n  (0, 3887)\t1\n  (0, 3629)\t1\n  (0, 3888)\t1\n  (0, 1531)\t1\n  (0, 4439)\t2\n  (0, 4840)\t1\n  (0, 4843)\t1\n  (0, 3492)\t1\n  (0, 1412)\t1\n  (0, 483)\t1\n  (0, 256)\t1\n  (0, 3588)\t1\n  (0, 4146)\t1\n  (0, 5608)\t2\n  (0, 5974)\t1\n  (0, 5752)\t1\n  (0, 5781)\t1\n  (0, 4814)\t1\n  (0, 2401)\t1\n  (0, 1260)\t1\n  (0, 15)\t1\n  (0, 832)\t37\n  (0, 2540)\t471\n  (0, 2770)\t604\n  (0, 1693)\t1\n  (0, 1934)\t2\n  (0, 3473)\t2\n  (0, 3419)\t1\n  (0, 1944)\t1\n  (0, 33)\t1\n  (0, 2566)\t8\n  (0, 3739)\t11\n  (0, 474)\t57\n  (0, 2715)\t313\n  (0, 2391)\t1\n  (0, 3172)\t93\n  (0, 2892)\t15\n  (0, 3379)\t3\n  (0, 239)\t6\n  (0, 3284)\t9\n  (0, 3481)\t4\n  (0, 471)\t8\n  (0, 2718)\t38\n  (0, 830)\t1\n  (0, 1197)\t3\n  :\t:\n  (0, 2093)\t1\n  (0, 2108)\t1\n  (0, 1600)\t1\n  (0, 2931)\t1\n  (0, 195)\t1\n  (0, 130)\t1\n  (0, 543)\t1\n  (0, 1308)\t1\n  (0, 3590)\t1\n  (0, 1335)\t1\n  (0, 1504)\t1\n  (0, 112)\t1\n  (0, 3662)\t1\n  (0, 3477)\t1\n  (0, 2656)\t1\n  (0, 825)\t1\n  (0, 3539)\t1\n  (0, 2147)\t1\n  (0, 2222)\t1\n  (0, 1500)\t1\n  (0, 741)\t1\n  (0, 2958)\t1\n  (0, 3475)\t1\n  (0, 323)\t1\n  (0, 2726)\t1\n  (0, 2347)\t1\n  (0, 5044)\t7\n  (0, 2955)\t1\n  (0, 4184)\t5\n  (0, 7234)\t2\n  (0, 5345)\t7\n  (0, 2862)\t32\n  (0, 5186)\t67\n  (0, 3871)\t21\n  (0, 5659)\t22\n  (0, 3542)\t129\n  (0, 12)\t6\n  (0, 3872)\t6\n  (0, 2467)\t61\n  (0, 4257)\t773\n  (0, 4585)\t227\n  (0, 2112)\t7\n  (0, 5086)\t50\n  (0, 47)\t5\n  (0, 4236)\t6\n  (0, 3270)\t265\n  (0, 4379)\t6\n  (0, 266)\t218\n  (0, 5428)\t205\n  (0, 81)\t5\n  :\t:\n  (0, 4281)\t2\n  (0, 1397)\t1\n  (0, 1458)\t1\n  (0, 3420)\t1\n  (0, 122)\t1\n  (0, 3674)\t1\n  (0, 3529)\t1\n  (0, 1675)\t1\n  (0, 4495)\t1\n  (0, 3817)\t1\n  (0, 6747)\t1\n  (0, 6604)\t2\n  (0, 2974)\t1\n  (0, 4526)\t1\n  (0, 7256)\t1\n  (0, 1969)\t1\n  (0, 6681)\t1\n  (0, 3789)\t1\n  (0, 6715)\t1\n  (0, 6612)\t1\n  (0, 4738)\t1\n  (0, 6843)\t1\n  (0, 1630)\t1\n  (0, 4277)\t1\n  (0, 4838)\t1\n  (0, 0)\t1\n  (0, 961)\t6\n  (0, 1665)\t58\n  (0, 1365)\t28\n  (0, 1395)\t29\n  (0, 1081)\t1\n  (0, 1234)\t1\n  (0, 2207)\t1\n  (0, 2173)\t1\n  (0, 1243)\t1\n  (0, 1)\t1\n  (0, 1620)\t1\n  (0, 116)\t1\n  (0, 999)\t1\n  (0, 1565)\t49\n  (0, 696)\t2\n  (0, 1913)\t4\n  (0, 1569)\t8\n  (0, 795)\t8\n  (0, 1305)\t7\n  (0, 698)\t5\n  (0, 1542)\t5\n  (0, 2093)\t3\n  (0, 1410)\t115\n  (0, 2166)\t23\n  :\t:\n  (0, 7)\t1\n  (0, 1660)\t1\n  (0, 1999)\t1\n  (0, 394)\t2\n  (0, 1106)\t1\n  (0, 908)\t1\n  (0, 2335)\t1\n  (0, 2013)\t1\n  (0, 2198)\t1\n  (0, 1313)\t1\n  (0, 327)\t1\n  (0, 233)\t1\n  (0, 2053)\t1\n  (0, 2179)\t1\n  (0, 1740)\t1\n  (0, 1866)\t1\n  (0, 466)\t1\n  (0, 2230)\t1\n  (0, 878)\t1\n  (0, 249)\t1\n  (0, 1804)\t1\n  (0, 303)\t1\n  (0, 1125)\t1\n  (0, 866)\t1\n  (0, 2062)\t1\n  (0, 1832)\t1\n  (0, 2537)\t25\n  (0, 980)\t2\n  (0, 3406)\t103\n  (0, 2590)\t1\n  (0, 1476)\t13\n  (0, 3222)\t1\n  (0, 1292)\t7\n  (0, 2924)\t3\n  (0, 3207)\t5\n  (0, 1311)\t5\n  (0, 2647)\t3\n  (0, 2868)\t112\n  (0, 2044)\t81\n  (0, 1044)\t5\n  (0, 2862)\t1\n  (0, 2038)\t25\n  (0, 1605)\t5\n  (0, 2369)\t29\n  (0, 218)\t2\n  (0, 2092)\t2\n  (0, 2467)\t25\n  (0, 3532)\t2\n  (0, 3467)\t1\n  (0, 3270)\t3\n  :\t:\n  (0, 2937)\t1\n  (0, 1040)\t1\n  (0, 435)\t1\n  (0, 1773)\t1\n  (0, 2341)\t1\n  (0, 351)\t1\n  (0, 3424)\t1\n  (0, 1954)\t1\n  (0, 3157)\t1\n  (0, 301)\t1\n  (0, 1184)\t1\n  (0, 2114)\t1\n  (0, 2571)\t1\n  (0, 2634)\t1\n  (0, 1593)\t1\n  (0, 2572)\t1\n  (0, 2636)\t1\n  (0, 2900)\t1\n  (0, 2635)\t1\n  (0, 1121)\t1\n  (0, 1594)\t1\n  (0, 3221)\t1\n  (0, 1313)\t1\n  (0, 2925)\t1\n  (0, 630)\t1\n  (0, 6433)\t21\n  (0, 3879)\t103\n  (0, 8736)\t1420\n  (0, 4374)\t917\n  (0, 6632)\t487\n  (0, 2185)\t26\n  (0, 4760)\t1413\n  (0, 4162)\t98\n  (0, 8280)\t1198\n  (0, 4861)\t588\n  (0, 2750)\t786\n  (0, 2103)\t5\n  (0, 4711)\t107\n  (0, 7069)\t813\n  (0, 7590)\t855\n  (0, 1450)\t21\n  (0, 9648)\t150\n  (0, 7921)\t48\n  (0, 8548)\t121\n  (0, 9204)\t267\n  (0, 9434)\t2\n  (0, 8309)\t128\n  (0, 11022)\t1282\n  (0, 1328)\t34\n  (0, 2873)\t31\n  :\t:\n  (0, 5538)\t1\n  (0, 2516)\t1\n  (0, 11278)\t1\n  (0, 2386)\t1\n  (0, 7388)\t1\n  (0, 7938)\t1\n  (0, 3500)\t1\n  (0, 4758)\t1\n  (0, 11557)\t1\n  (0, 1272)\t1\n  (0, 3039)\t1\n  (0, 5346)\t1\n  (0, 9188)\t1\n  (0, 1515)\t1\n  (0, 8716)\t1\n  (0, 9368)\t1\n  (0, 9277)\t1\n  (0, 4279)\t1\n  (0, 1861)\t1\n  (0, 8657)\t1\n  (0, 5662)\t1\n  (0, 8884)\t1\n  (0, 4793)\t1\n  (0, 9696)\t1\n  (0, 2846)\t1\n"
    }
   ],
   "source": [
    "#get vocab and counts for Kant texts\n",
    "\n",
    "purereason_text = read_file('texts/kant/purereason.txt')\n",
    "purereason_ngrams = get_most_common_words(purereason_text)\n",
    "\n",
    "practicalreason_text = read_file('texts/kant/practicalreason.txt')\n",
    "practicalreason_ngrams = get_most_common_words(practicalreason_text)\n",
    "\n",
    "judgment_text = read_file('texts/kant/judgment.txt')\n",
    "judgment_ngrams = get_most_common_words(judgment_text)\n",
    "\n",
    "morals_text = read_file('texts/kant/metaphysicsofmorals.txt')\n",
    "morals_ngrams = get_most_common_words(morals_text)\n",
    "\n",
    "prolegomena_text = read_file('texts/kant/prolegomena.txt')\n",
    "prolegomena_ngrams = get_most_common_words(prolegomena_text)\n",
    "\n",
    "#add all kant texts into a single textstream\n",
    "kant_text = purereason_text + practicalreason_text + judgment_text + morals_text + prolegomena_text\n",
    "kant_ngrams = get_most_common_words(kant_text)\n",
    "\n",
    "#build dictionaries\n",
    "purereason_dictlist = [format_tuple(item) for item in purereason_ngrams ]\n",
    "practicalreason_dictlist = [format_tuple(item) for item in practicalreason_ngrams ]\n",
    "morals_dictlist = [format_tuple(item) for item in morals_ngrams ]\n",
    "prolegomena_dictlist = [format_tuple(item) for item in prolegomena_ngrams ]\n",
    "judgment_dictlist = [format_tuple(item) for item in judgment_ngrams ]\n",
    "kant_dictlist = [format_tuple(item) for item in kant_ngrams ]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vocab and counts for hume texts\n",
    "\n",
    "enquiry_text = read_file('texts/hume/enquiryhumanunderstanding.txt')\n",
    "enquiry_ngrams = get_most_common_words(enquiry_text)\n",
    "\n",
    "humannature_text = read_file('texts/hume/humannature.txt')\n",
    "humannature_ngrams = get_most_common_words(humannature_text)\n",
    "\n",
    "naturalreligion_text = read_file('texts/hume/naturalreligion.txt')\n",
    "naturalreligion_ngrams = get_most_common_words(naturalreligion_text)\n",
    "\n",
    "humemorals_text = read_file('texts/hume/principlesofmorals.txt')\n",
    "humemorals_ngrams = get_most_common_words(humemorals_text)\n",
    "\n",
    "#add all hume texts into a single textstream\n",
    "hume_text = enquiry_text + humannature_text + naturalreligion_text + humemorals_text\n",
    "hume_ngrams = get_most_common_words(hume_text)\n",
    "\n",
    "#build dictionaries\n",
    "enquiry_dictlist = [format_tuple(item) for item in enquiry_ngrams ]\n",
    "humannature_dictlist = [format_tuple(item) for item in humannature_ngrams ]\n",
    "naturalreligion_dictlist = [format_tuple(item) for item in naturalreligion_ngrams ]\n",
    "humemorals_dictlist = [format_tuple(item) for item in humemorals_ngrams ]\n",
    "hume_dictlist = [format_tuple(item) for item in hume_ngrams ]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vocab and counts for nietzsche texts\n",
    "\n",
    "alltoohuman_text = read_file('texts/nietzsche/alltoohuman.txt')\n",
    "alltoohuman_ngrams = get_most_common_words(alltoohuman_text)\n",
    "\n",
    "antichrist_text = read_file('texts/nietzsche/antichrist.txt')\n",
    "antichrist_ngrams = get_most_common_words(antichrist_text)\n",
    "\n",
    "beyond_text = read_file('texts/nietzsche/beyondgoodandevil.txt')\n",
    "beyond_ngrams = get_most_common_words(beyond_text)\n",
    "\n",
    "tragedy_text = read_file('texts/nietzsche/birthoftragedy.txt')\n",
    "tragedy_ngrams = get_most_common_words(tragedy_text)\n",
    "\n",
    "eccehomo_text = read_file('texts/nietzsche/eccehomo.txt')\n",
    "eccehomo_ngrams = get_most_common_words(eccehomo_text)\n",
    "\n",
    "nietzschemorals_text = read_file('texts/nietzsche/geneaologyofmorals.txt')\n",
    "nietzschemorals_ngrams = get_most_common_words(nietzschemorals_text)\n",
    "\n",
    "joyfulwisdom_text = read_file('texts/nietzsche/joyfulwisdom.txt')\n",
    "joyfulwisdom_ngrams = get_most_common_words(joyfulwisdom_text)\n",
    "\n",
    "zarathustra_text = read_file('texts/nietzsche/zarathustra.txt')\n",
    "zarathustra_ngrams = get_most_common_words(zarathustra_text)\n",
    "\n",
    "#add all nietzsche texts into a single textstream\n",
    "nietzsche_text = alltoohuman_text + antichrist_text + beyond_text\\\n",
    "                 + tragedy_text + eccehomo_text + nietzschemorals_text\\\n",
    "                 + joyfulwisdom_text + zarathustra_text\n",
    "\n",
    "nietzsche_ngrams = get_most_common_words(nietzsche_text)\n",
    "\n",
    "#build dictionaries\n",
    "alltoohuman_dictlist = [format_tuple(item) for item in alltoohuman_ngrams ]\n",
    "antichrist_dictlist = [format_tuple(item) for item in antichrist_ngrams ]\n",
    "beyond_dictlist = [format_tuple(item) for item in beyond_ngrams ]\n",
    "tragedy_dictlist = [format_tuple(item) for item in tragedy_ngrams ]\n",
    "eccehomo_dictlist = [format_tuple(item) for item in eccehomo_ngrams ]\n",
    "nietzschemorals_dictlist = [format_tuple(item) for item in nietzschemorals_ngrams ]\n",
    "joyfulwisdom_dictlist = [format_tuple(item) for item in joyfulwisdom_ngrams ]\n",
    "zarathustra_dictlist = [format_tuple(item) for item in zarathustra_ngrams ]\n",
    "nietzsche_dictlist = [format_tuple(item) for item in nietzsche_ngrams ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build final dictinoary object and save off as JSON file\n",
    "word_dictionary = { 'Hume: All': hume_dictlist,\n",
    "                    'Hume: An Enquiry Concerning Human Understanding' : enquiry_dictlist,\n",
    "                    'Hume: An Enquiry Concerning the Principles of Morals':humemorals_dictlist,\n",
    "                    'Hume: Dialogues Concerning Natural Religion': naturalreligion_dictlist,\n",
    "                    'Hume: Treatise of Human Nature':humannature_dictlist, \n",
    "                    'Kant: All': kant_dictlist,\n",
    "                    'Kant: Critique of Judgment' : judgment_dictlist,\n",
    "                    'Kant: Critique of Pure Reason': purereason_dictlist,\n",
    "                    'Kant: Critique of Practical Reason':practicalreason_dictlist,\n",
    "                    'Kant: Grounding for a Metaphysics of Morals':morals_dictlist, \n",
    "                    'Kant: Prolegomena for any Future Metaphyics': prolegomena_dictlist,\n",
    "                    'Nietzsche: All': nietzsche_dictlist,\n",
    "                    'Nietzsche: Anti-Christ' : antichrist_dictlist,\n",
    "                    'Nietzsche: Beyond Good and Evil': beyond_dictlist,\n",
    "                    'Nietzsche: Birth of Tragedy':tragedy_dictlist,\n",
    "                    'Nietzsche: Ecce Homo':eccehomo_dictlist, \n",
    "                    'Nietzsche: Geneaology of Morals': nietzschemorals_dictlist,\n",
    "                    'Nietzsche: Human, All Too Human': alltoohuman_dictlist,\n",
    "                    'Nietzsche: Joyful Wisdom': joyfulwisdom_dictlist,\n",
    "                    'Nietzsche: Thus Spoke Zarathustra': zarathustra_dictlist}\n",
    "\n",
    "with open('static/wordcloud.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(word_dictionary,f,ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}