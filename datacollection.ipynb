{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitpythondataconda8971416e9bae4e8197b8a061b72f9dc8",
   "display_name": "Python 3.6.9 64-bit ('PythonData': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "# import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_most_common_words(textStream):\n",
    "\n",
    "    #init vectorizer\n",
    "    ngram_vectors = CountVectorizer(analyzer='word', \n",
    "                                    ngram_range=(1, 1), \n",
    "                                    min_df=1,\n",
    "                                    stop_words='english')\n",
    "    \n",
    "    #make textStream into an iterable for fit_transform\n",
    "    textStream = [textStream]\n",
    "    \n",
    "    #build vectors\n",
    "    X = ngram_vectors.fit_transform(textStream)\n",
    "\n",
    "    #build ngrab vocabulary\n",
    "    vocab = ngram_vectors.get_feature_names()\n",
    "\n",
    "    #get ngram counts\n",
    "    counts = X.sum(axis=0).A1\n",
    "\n",
    "    #get frequency distribution of all ngrams and their respective counts\n",
    "    freq_distribution = Counter(dict(zip(vocab, counts)))\n",
    "\n",
    "    #get 100 most common ngrams, with its respective count\n",
    "    most_common_words = freq_distribution.most_common(100)\n",
    "\n",
    "    return most_common_words\n",
    "\n",
    "def read_file(text_file):\n",
    "    file = open(text_file,mode='r',encoding='UTF-8')\n",
    "    file_contents = file.read()\n",
    "    file.close()\n",
    "    return file_contents\n",
    "\n",
    "def format_tuple(input_tuple):\n",
    "    dict_entry = { 'text': input_tuple[0],\n",
    "                    'value': str(input_tuple[1])}\n",
    "    return dict_entry\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#get vocab and counts for Kant texts\n",
    "\n",
    "purereason_text = read_file('texts/kant/purereason.txt')\n",
    "purereason_ngrams = get_most_common_words(purereason_text)\n",
    "\n",
    "practicalreason_text = read_file('texts/kant/practicalreason.txt')\n",
    "practicalreason_ngrams = get_most_common_words(practicalreason_text)\n",
    "\n",
    "judgment_text = read_file('texts/kant/judgment.txt')\n",
    "judgment_ngrams = get_most_common_words(judgment_text)\n",
    "\n",
    "morals_text = read_file('texts/kant/metaphysicsofmorals.txt')\n",
    "morals_ngrams = get_most_common_words(morals_text)\n",
    "\n",
    "prolegomena_text = read_file('texts/kant/prolegomena.txt')\n",
    "prolegomena_ngrams = get_most_common_words(prolegomena_text)\n",
    "\n",
    "#add all kant texts into a single textstream\n",
    "kant_text = purereason_text + practicalreason_text + judgment_text + morals_text + prolegomena_text\n",
    "kant_ngrams = get_most_common_words(kant_text)\n",
    "\n",
    "#build dictionaries\n",
    "purereason_dictlist = [format_tuple(item) for item in purereason_ngrams ]\n",
    "practicalreason_dictlist = [format_tuple(item) for item in practicalreason_ngrams ]\n",
    "morals_dictlist = [format_tuple(item) for item in morals_ngrams ]\n",
    "prolegomena_dictlist = [format_tuple(item) for item in prolegomena_ngrams ]\n",
    "judgment_dictlist = [format_tuple(item) for item in judgment_ngrams ]\n",
    "kant_dictlist = [format_tuple(item) for item in kant_ngrams ]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vocab and counts for hume texts\n",
    "\n",
    "enquiry_text = read_file('texts/hume/enquiryhumanunderstanding.txt')\n",
    "enquiry_ngrams = get_most_common_words(enquiry_text)\n",
    "\n",
    "humannature_text = read_file('texts/hume/humannature.txt')\n",
    "humannature_ngrams = get_most_common_words(humannature_text)\n",
    "\n",
    "naturalreligion_text = read_file('texts/hume/naturalreligion.txt')\n",
    "naturalreligion_ngrams = get_most_common_words(naturalreligion_text)\n",
    "\n",
    "humemorals_text = read_file('texts/hume/principlesofmorals.txt')\n",
    "humemorals_ngrams = get_most_common_words(humemorals_text)\n",
    "\n",
    "#add all hume texts into a single textstream\n",
    "hume_text = enquiry_text + humannature_text + naturalreligion_text + humemorals_text\n",
    "hume_ngrams = get_most_common_words(hume_text)\n",
    "\n",
    "#build dictionaries\n",
    "enquiry_dictlist = [format_tuple(item) for item in enquiry_ngrams ]\n",
    "humannature_dictlist = [format_tuple(item) for item in humannature_ngrams ]\n",
    "naturalreligion_dictlist = [format_tuple(item) for item in naturalreligion_ngrams ]\n",
    "humemorals_dictlist = [format_tuple(item) for item in humemorals_ngrams ]\n",
    "hume_dictlist = [format_tuple(item) for item in hume_ngrams ]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vocab and counts for nietzsche texts\n",
    "\n",
    "alltoohuman_text = read_file('texts/nietzsche/alltoohuman.txt')\n",
    "alltoohuman_ngrams = get_most_common_words(alltoohuman_text)\n",
    "\n",
    "antichrist_text = read_file('texts/nietzsche/antichrist.txt')\n",
    "antichrist_ngrams = get_most_common_words(antichrist_text)\n",
    "\n",
    "beyond_text = read_file('texts/nietzsche/beyondgoodandevil.txt')\n",
    "beyond_ngrams = get_most_common_words(beyond_text)\n",
    "\n",
    "tragedy_text = read_file('texts/nietzsche/birthoftragedy.txt')\n",
    "tragedy_ngrams = get_most_common_words(tragedy_text)\n",
    "\n",
    "eccehomo_text = read_file('texts/nietzsche/eccehomo.txt')\n",
    "eccehomo_ngrams = get_most_common_words(eccehomo_text)\n",
    "\n",
    "nietzschemorals_text = read_file('texts/nietzsche/geneaologyofmorals.txt')\n",
    "nietzschemorals_ngrams = get_most_common_words(nietzschemorals_text)\n",
    "\n",
    "joyfulwisdom_text = read_file('texts/nietzsche/joyfulwisdom.txt')\n",
    "joyfulwisdom_ngrams = get_most_common_words(joyfulwisdom_text)\n",
    "\n",
    "zarathustra_text = read_file('texts/nietzsche/zarathustra.txt')\n",
    "zarathustra_ngrams = get_most_common_words(zarathustra_text)\n",
    "\n",
    "#add all nietzsche texts into a single textstream\n",
    "nietzsche_text = alltoohuman_text + antichrist_text + beyond_text\\\n",
    "                 + tragedy_text + eccehomo_text + nietzschemorals_text\\\n",
    "                 + joyfulwisdom_text + zarathustra_text\n",
    "\n",
    "nietzsche_ngrams = get_most_common_words(nietzsche_text)\n",
    "\n",
    "#build dictionaries\n",
    "alltoohuman_dictlist = [format_tuple(item) for item in alltoohuman_ngrams ]\n",
    "antichrist_dictlist = [format_tuple(item) for item in antichrist_ngrams ]\n",
    "beyond_dictlist = [format_tuple(item) for item in beyond_ngrams ]\n",
    "tragedy_dictlist = [format_tuple(item) for item in tragedy_ngrams ]\n",
    "eccehomo_dictlist = [format_tuple(item) for item in eccehomo_ngrams ]\n",
    "nietzschemorals_dictlist = [format_tuple(item) for item in nietzschemorals_ngrams ]\n",
    "joyfulwisdom_dictlist = [format_tuple(item) for item in joyfulwisdom_ngrams ]\n",
    "zarathustra_dictlist = [format_tuple(item) for item in zarathustra_ngrams ]\n",
    "nietzsche_dictlist = [format_tuple(item) for item in nietzsche_ngrams ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file = { 'Hume: All': hume_dictlist,\n",
    "              'Hume: An Enquiry Concerning Human Understanding' : enquiry_dictlist,\n",
    "              'Hume: An Enquiry Concerning the Principles of Morals':humemorals_dictlist,\n",
    "              'Hume: Dialogues Concerning Natural Religion': naturalreligion_dictlist,\n",
    "              'Hume: Treatise of Human Nature':humannature_dictlist, \n",
    "              'Kant: All': kant_dictlist,\n",
    "              'Kant: Critique of Judgment' : judgment_dictlist,\n",
    "              'Kant: Critique of Pure Reason': purereason_dictlist,\n",
    "              'Kant: Critique of Practical Reason':practicalreason_dictlist,\n",
    "              'Kant: Grounding for a Metaphysics of Morals':morals_dictlist, \n",
    "              'Kant: Prolegomena for any Future Metaphyics': prolegomena_dictlist,\n",
    "              'Nietzsche: All': nietzsche_dictlist,\n",
    "              'Nietzsche: Anti-Christ' : antichrist_dictlist,\n",
    "              'Nietzsche: Beyond Good and Evil': beyond_dictlist,\n",
    "              'Nietzsche: Birth of Tragedy':tragedy_dictlist,\n",
    "              'Nietzsche: Ecce Homo':eccehomo_dictlist, \n",
    "              'Nietzsche: Geneaology of Morals': nietzschemorals_dictlist,\n",
    "              'Nietzsche: Human, All Too Human': alltoohuman_dictlist,\n",
    "              'Nietzsche: Joyful Wisdom': joyfulwisdom_dictlist,\n",
    "              'Nietzsche: Thus Spoke Zarathustra': zarathustra_dictlist}\n",
    "\n",
    "with open('static/wordcloud.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(json_file,f,ensure_ascii=False, indent=4)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}